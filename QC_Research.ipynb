{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izxJH6A4rEFd"
      },
      "outputs": [],
      "source": [
        "!pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iJHVp4Yqkg6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import cmath\n",
        "import qiskit\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import pandas\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBpGHHFlq1NA"
      },
      "outputs": [],
      "source": [
        "#Convenience function\n",
        "# Returns 0 for all numbers except when i=j (like kronicker delta)\n",
        "def one_hot(i, n):\n",
        "    return [int(j == i) for j in range(n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RDAgfOsrzD9"
      },
      "outputs": [],
      "source": [
        "one_hot(2,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiTX4MOlr3ZQ"
      },
      "outputs": [],
      "source": [
        "#Class representing quantum gates. Use the static methods to construct new\n",
        "# objects.\n",
        "class Gate:\n",
        "    types = [\"rx\", \"ry\", \"rz\", \"cx\", \"xc\", \"stop\"]\n",
        "    def __init__(self, gate_type, target, angle, n_qubits):\n",
        "        self.gate_type = gate_type\n",
        "        self.target = target  #target qubit\n",
        "        self.angle = angle    #phase angles\n",
        "        self.n_qubits = n_qubits\n",
        "\n",
        "    def is_cx(self):\n",
        "        return self.gate_type in [\"cx\", \"xc\"]\n",
        "\n",
        "    def is_stop(self):\n",
        "        return self.gate_type == \"stop\"\n",
        "\n",
        "    def inverse(self):\n",
        "        if self.is_cx() or self.is_stop(): return self\n",
        "        return Gate(self.gate_type, self.target, -self.angle, self.n_qubits)\n",
        "\n",
        "    def encode(self):\n",
        "        i1 = Gate.types.index(self.gate_type)\n",
        "        if i1 == -1: raise RuntimeError()\n",
        "        output = one_hot(i1, len(Gate.types))\n",
        "        output.extend(one_hot(self.target, self.n_qubits))\n",
        "        output.extend([self.angle])\n",
        "        return output\n",
        "\n",
        "    def to_string(self):\n",
        "        if self.is_stop(): return \"STOP\"\n",
        "        if self.is_cx():\n",
        "            control = self.target\n",
        "            target = control + 1\n",
        "            if self.gate_type == \"xc\":\n",
        "                control -= 1\n",
        "                target += 1\n",
        "            return \"CX control=\" + str(control) + \" target=\" + str(target)\n",
        "        return self.gate_type.upper() + \" target=\" + str(self.target) + \\\n",
        "        \" angle=\" + str(self.angle)\n",
        "\n",
        "    @staticmethod\n",
        "    def decode(vec):\n",
        "        vec_type = vec[0:len(Gate.types)]\n",
        "        vec_index = vec[len(Gate.types):-1]\n",
        "        gate_type = Gate.types[vec_type.index(max(vec_type))]\n",
        "        target = vec_index.index(max(vec_index))\n",
        "        return Gate(gate_type, target, vec[-1], len(vec_index))\n",
        "\n",
        "        #CX requires control and target to be on nearest neighbor qubits\n",
        "    @staticmethod\n",
        "    def CX(control, target, n_qubits):\n",
        "        if target == control + 1:\n",
        "            return Gate(\"cx\", control, 0, n_qubits)\n",
        "        if control == target + 1:\n",
        "            return Gate(\"xc\", target, 0, n_qubits)\n",
        "        raise RuntimeError()\n",
        "\n",
        "    @staticmethod\n",
        "    def RY(target, angle, n_qubits):\n",
        "        return Gate(\"ry\", target, angle, n_qubits)\n",
        "\n",
        "    @staticmethod\n",
        "    def RX(target, angle, n_qubits):\n",
        "        return Gate(\"rx\", target, angle, n_qubits)\n",
        "\n",
        "    @staticmethod\n",
        "    def RZ(target, angle, n_qubits):\n",
        "        return Gate(\"rz\", target, angle, n_qubits)\n",
        "\n",
        "    @staticmethod\n",
        "    def STOP(n_qubits):\n",
        "        return Gate(\"stop\", -1, 0, n_qubits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SiVvJJ8sf8Q"
      },
      "outputs": [],
      "source": [
        "gate = Gate('cx', target=1, angle=None, n_qubits=2)\n",
        "print(gate.is_cx())\n",
        "print(gate.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4J657Jusl76"
      },
      "outputs": [],
      "source": [
        "#Helper function\n",
        "def apply_rotation_gate(gate, state, index):\n",
        "    output = [None for _ in range(len(state))]\n",
        "    for i in range(len(output)):\n",
        "        if output[i] is not None: continue\n",
        "        e0 = state[i]\n",
        "        e1 = state[i + (1 << index)]\n",
        "        output[i] = gate[0][0] * e0 + gate[0][1] * e1\n",
        "        output[i + (1 << index)] = gate[1][0] * e0 + gate[1][1] * e1\n",
        "    return output\n",
        "\n",
        "#Helper function\n",
        "def apply_cx_gate(state, control, target):\n",
        "    output = [None for _ in range(len(state))]\n",
        "    for i in range(len(output)):\n",
        "        if (i >> control) % 2: output[i] = state[i ^ (1 << target)]\n",
        "        else: output[i] = state[i]\n",
        "    return output\n",
        "\n",
        "\n",
        "#Given Gate object [gate] and list of complex amplitudes [state] representing a\n",
        "# quantum state, returns a new list of complex amplitudes representing the\n",
        "# result of applying quantum gate [gate] to quantum state [state]. Does not\n",
        "# modify [state].\n",
        "def apply_gate(gate, state):\n",
        "    if gate.gate_type == \"rx\":\n",
        "        mat = [[math.cos(gate.angle / 2), -1.0j * math.sin(gate.angle / 2)], \\\n",
        "               [-1.0j * math.sin(gate.angle / 2), math.cos(gate.angle / 2)]]\n",
        "        return apply_rotation_gate(mat, state, gate.target)\n",
        "    if gate.gate_type == \"ry\":\n",
        "        mat = [[math.cos(gate.angle / 2), -math.sin(gate.angle / 2)], \\\n",
        "               [math.sin(gate.angle / 2), math.cos(gate.angle / 2)]]\n",
        "        return apply_rotation_gate(mat, state, gate.target)\n",
        "    if gate.gate_type == \"rz\":\n",
        "        mat = [[cmath.exp(-1.0j * gate.angle / 2), 0], \\\n",
        "               [0, cmath.exp(1.0j * gate.angle / 2)]]\n",
        "        return apply_rotation_gate(mat, state, gate.target)\n",
        "    if gate.gate_type == \"cx\":\n",
        "        return apply_cx_gate(state, gate.target, gate.target + 1)\n",
        "    if gate.gate_type == \"xc\":\n",
        "        return apply_cx_gate(state, gate.target + 1, gate.target)\n",
        "    if gate.gate_type == \"stop\":\n",
        "        return [a for a in state]     #WHY WOULD THIS BE THERE?\n",
        "\n",
        "#Helper function\n",
        "def validate_apply_gate():\n",
        "    circuit = qiskit.QuantumCircuit(2)\n",
        "    circuit.ry(1, 0)\n",
        "    circuit.rz(2, 1)\n",
        "    circuit.rx(3, 0)\n",
        "    circuit.rx(4, 1)\n",
        "    circuit.cx(0, 1)\n",
        "    circuit.ry(2, 0)\n",
        "    circuit.ry(1, 1)\n",
        "    circuit.cx(1, 0)\n",
        "    simulator = qiskit.Aer.get_backend(\"statevector_simulator\")\n",
        "    sv1 = np.array(simulator.run(circuit).result().get_statevector())\n",
        "    sv2 = one_hot(0, 4)\n",
        "    for gate in [Gate.RY(0, 1, 2), Gate.RZ(1, 2, 2), Gate.RX(0, 3, 2),\n",
        "    Gate.RX(1, 4, 2), Gate.CX(0, 1, 2), Gate.RY(0, 2, 2), Gate.RY(1, 1, 2),\n",
        "    Gate.CX(1, 0, 2)]:\n",
        "        sv2 = apply_gate(gate, sv2)\n",
        "    sv2 = np.array(sv2)\n",
        "    delta = sv1 - sv2\n",
        "    assert(delta.dot(delta) < 0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wZqonBpuivB"
      },
      "outputs": [],
      "source": [
        "#Encodes a quantum state [state] into a list of real numbers.\n",
        "def encode_state(state):\n",
        "    output = [abs(s) for s in state]\n",
        "    output.extend([cmath.phase(s) / math.pi for s in state])\n",
        "    return output\n",
        "\n",
        "#Takes the encoded form of a quantum state (output from encode_state function)\n",
        "# and returns it back to a list of complex amplitudes. Guaranteed that for\n",
        "# all lists of complex numbers [state],\n",
        "#   state == decode_state(encode_state(state))\n",
        "# up to rounding error\n",
        "def decode_state(state):\n",
        "    amps = state[0:len(state) >> 1]\n",
        "    phases = state[len(state) >> 1:]\n",
        "    output = [a * cmath.exp(p * math.pi * 1.0j) for a, p in zip(amps, phases)]\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HEaTY9iuqPv"
      },
      "outputs": [],
      "source": [
        "#Generates a random sequence of gates for [n_qubits] qubits, including exactly\n",
        "# [num_cx] CX gates.\n",
        "def generate_gate_sequence(num_cx, n_qubits):\n",
        "    output = []\n",
        "    for i in range(n_qubits):\n",
        "        types = random.sample([\"rx\", \"ry\", \"rz\"], 2)\n",
        "        a1 = random.uniform(0, math.pi)\n",
        "        a2 = random.uniform(-math.pi, math.pi)\n",
        "        output.append(Gate.RY(i, a1, n_qubits))\n",
        "        output.append(Gate.RZ(i, a2, n_qubits))\n",
        "    for _ in range(num_cx):\n",
        "        control = random.randint(0, n_qubits - 2)\n",
        "        target = control + 1\n",
        "        if random.randint(0, 1):\n",
        "            control += 1\n",
        "            target -= 1\n",
        "        a1, a2, a3, a4 = [random.uniform(-math.pi, math.pi) for _ in range(4)]\n",
        "        output.append(Gate.CX(control, target, n_qubits))\n",
        "        output.append(Gate.RY(control, a1, n_qubits))\n",
        "        output.append(Gate.RZ(control, a2, n_qubits))\n",
        "        output.append(Gate.RY(target, a3, n_qubits))\n",
        "        output.append(Gate.RX(target, a4, n_qubits))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDcmKOQo1PKC"
      },
      "outputs": [],
      "source": [
        "#Helper function\n",
        "def noisy_start(n_qubits, factor=0.1):\n",
        "    a = np.array([int(i == 0) for i in range(1 << n_qubits)]).astype(\"complex\")\n",
        "    noise = np.array([random.gauss(0, 1) * cmath.exp(random.random() * 2.0j * cmath.pi) for _ in range(8)])\n",
        "    noise *= factor\n",
        "    a += noise\n",
        "    norm = sum(abs(x) ** 2 for x in a) ** 0.5\n",
        "    a /= norm\n",
        "    return a\n",
        "\n",
        "#Returns a 2-tuple (training, testing). Both [training] and [testing] are lists\n",
        "# of sequences of the form reward, state, gate, reward, state, gate, ...\n",
        "# See the demo file for an example\n",
        "def generate_dataset(n_qubits, count, frac_testing=0.2, noise=0.1):\n",
        "    training = []\n",
        "    testing = []\n",
        "    for i in range(count):\n",
        "        for num_cx in range(2 * n_qubits):\n",
        "            #Alignment as follows:\n",
        "            # index:  0      1      2       3\n",
        "            # gates:  <stop> g0     g1      g2\n",
        "            # states: |0>    g0|0>  g1g0|0> g2g1g0|0>\n",
        "            # reward: 0, 0   f(g0|0>)\n",
        "            gates = generate_gate_sequence(num_cx, n_qubits)\n",
        "            states = [noisy_start(n_qubits, factor=noise).tolist()]\n",
        "            rewards = [(0, 0)]\n",
        "            cx_count = 0\n",
        "            start_fid = abs(states[0][0])\n",
        "            for g in gates:\n",
        "                s = apply_gate(g, states[-1])\n",
        "                states.append(s)\n",
        "                fid_to_go = start_fid - abs(s[0])\n",
        "                if g.is_cx(): cx_count += 1\n",
        "                rewards.append((fid_to_go, cx_count))\n",
        "            assert(cx_count == num_cx)\n",
        "            gates.insert(0, Gate.STOP(n_qubits))\n",
        "            zipped = []\n",
        "            for g, s, r in zip(gates, states, rewards):\n",
        "                zipped.extend([g.inverse().encode(), encode_state(s), r])\n",
        "            zipped.reverse()\n",
        "            assert(len(zipped) % 3 == 0)\n",
        "            if i > frac_testing * count: training.append(zipped)\n",
        "            else: testing.append(zipped)\n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5JIL7E71QEm"
      },
      "outputs": [],
      "source": [
        "#Helper function\n",
        "def validate_dataset(dataset):\n",
        "    for sequence in dataset:\n",
        "        assert(len(sequence) % 3 == 0)\n",
        "        for i in range(0, len(sequence) - 3, 3):\n",
        "            (f1, c1), s1, a1 = sequence[i:i + 3]\n",
        "            (f2, c2), s2, a2 = sequence[i + 3:i + 6]\n",
        "            s1 = decode_state(s1)\n",
        "            s2 = decode_state(s2)\n",
        "            a1 = Gate.decode(a1)\n",
        "            delta = np.array(apply_gate(a1, s1)) - np.array(s2)\n",
        "            assert(delta.dot(delta) < 0.0001)\n",
        "            assert(abs(f1 - f2 - (abs(s2[0]) - abs(s1[0]))) < 0.0001)\n",
        "            assert(c1 - c2 == int(a1.is_cx()))\n",
        "            if Gate.decode(a2).is_stop():\n",
        "                assert(abs(f2) < 0.0001)\n",
        "                assert(c2 == 0)\n",
        "\n",
        "#Converts [data] output from generate_dataset function into a list of batches.\n",
        "#Each batch contains [batch_size] subsequences taken from sequences in the\n",
        "# original dataset, where each subsequences contains [previews] previews of past\n",
        "# reward, state, gate triples, plus the reward and state token for the current\n",
        "# time step.\n",
        "def make_batches(data, n_qubits, previews=4, batch_size=60):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for seq in data:\n",
        "        seq_in = seq[:-1]\n",
        "        for i in range(0, len(seq) - 3, 3):\n",
        "            seq_input = seq_in[i:i + previews * 3 + 2]\n",
        "            while len(seq_input) < previews * 3 + 2:\n",
        "                seq_input.append(Gate.STOP(n_qubits).encode())\n",
        "                seq_input.extend(seq_input[-3:-1])\n",
        "            seq_output = [seq_input[j] for j in range(2, len(seq_input), 3)]\n",
        "            if i + len(seq_input) >= len(seq):\n",
        "                seq_output.append(Gate.STOP(n_qubits).encode())\n",
        "            else: seq_output.append(seq[i + len(seq_input)])\n",
        "            inputs.append(seq_input)\n",
        "            outputs.append(seq_output)\n",
        "    order = [i for i in range(len(inputs))]\n",
        "    random.shuffle(order)\n",
        "    output = []\n",
        "    for i in range(0, len(order) - batch_size, batch_size):\n",
        "        batch_x = [inputs[order[j]] for j in range(i, i + batch_size)]\n",
        "        batch_y = [outputs[order[j]] for j in range(i, i + batch_size)]\n",
        "        output.append((batch_x, batch_y))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDe1D26o1ZTP"
      },
      "outputs": [],
      "source": [
        "#Helper function\n",
        "def write_batches_to_file(batches, filename):\n",
        "    with open(filename, \"w\") as f:\n",
        "        for batch in batches:\n",
        "            f.write(json.dumps(batch) + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\" and \"training_data.json\" not in os.listdir():\n",
        "    validate_apply_gate()\n",
        "    training_data, testing_data = generate_dataset(3, 100)\n",
        "    validate_dataset(testing_data)\n",
        "    training_batches = make_batches(training_data, 3, previews=4)\n",
        "    testing_batches = make_batches(testing_data, 3, previews=4)\n",
        "    write_batches_to_file(training_batches, \"training_data.json\")\n",
        "    write_batches_to_file(testing_batches, \"testing_data.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVNuNPXIi_m8"
      },
      "outputs": [],
      "source": [
        "#Class for reading batches that have been written to a file.\n",
        "# Eg:\n",
        "#     stream = BatchStream(\"testing_data.json\")\n",
        "#     model = <model>\n",
        "#     loss_fn = <loss function>\n",
        "#     loss = 0\n",
        "#     while stream.hasNext():\n",
        "#         x, y = stream.next()\n",
        "#         prediction = model(x)\n",
        "#         loss += loss_fn(prediction, y)\n",
        "#     print(\"Total loss: \", loss)\n",
        "class BatchStream:\n",
        "    def __init__(self, filename):\n",
        "        self.f = open(filename)\n",
        "        self.buffer = None\n",
        "    def _pull(self):\n",
        "        if self.buffer is not None: return\n",
        "        line = self.f.readline()\n",
        "        if len(line) < 2: return\n",
        "        batch = json.loads(line)\n",
        "        self.buffer = batch\n",
        "    def hasNext(self):\n",
        "        self._pull()\n",
        "        return self.buffer is not None\n",
        "    def next(self):\n",
        "        self._pull()\n",
        "        if self.buffer is None: raise\n",
        "        output = self.buffer\n",
        "        self.buffer = None\n",
        "        return output\n",
        "    def close(self):\n",
        "        self.f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioC1TsYejrc2"
      },
      "outputs": [],
      "source": [
        "#Generate training and testing datasets. Each dataset is a list of sequences.\n",
        "# Each sequence is formatted as:\n",
        "#   reward, state, gate, reward, state, gate, ...\n",
        "# Reward is a 2-tuple (fidelity to go, number of CX remaining)\n",
        "# State is encoded version of the current quantum state\n",
        "# Gate is an encoded version of the gate to apply to that quantum state\n",
        "# The first state is the target state to be prepared, the last state is\n",
        "# approximately the basis state |0>\n",
        "#\n",
        "# param n_qubits: number of qubits in the system\n",
        "# param count: number of sequences for each CX count\n",
        "# param frac_testing: fraction of sequences put in the testing set\n",
        "# param noise: parameter representing how well the gate sequences prepare\n",
        "#     the target state. noise=0 means perfect preparation, noise > 1 means\n",
        "#     mostly noise. Empirically, noise=0.1 works pretty well.\n",
        "training, testing = generate_dataset(n_qubits=3, count=100, frac_testing=0.2, noise=0.1)\n",
        "\n",
        "#Example for how to interpret the output datasets.\n",
        "seq0 = training[0]\n",
        "(fidelity_to_go, num_cx), state, gate = seq0[0:3]\n",
        "print(\"Fidelity to go: \", fidelity_to_go)\n",
        "print(\"Number of CX gates remaining: \", num_cx)\n",
        "print(\"Current quantum state: \", decode_state(state))\n",
        "print(\"Best gate to apply: \", Gate.decode(gate).to_string())\n",
        "(fidelity_to_go, num_cx), state, gate = seq0[3:6] #Changed error\n",
        "print(\"Resultant quantum state: \", decode_state(state))\n",
        "print(\"Next gate to apply: \", Gate.decode(gate).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(training))\n",
        "print(len(training[0]))"
      ],
      "metadata": {
        "id": "tSDB92hgEcGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmEVjsOop-OC"
      },
      "outputs": [],
      "source": [
        "n_qubits = 4  #variable\n",
        "batch = make_batches(training, n_qubits, previews=4, batch_size=60)\n",
        "write_batches_to_file(batch, 'QCR') #Put name of any filename you want batch stored as"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to read the batches:\n",
        "# test = BatchStream(\"testing_data.json\")\n",
        "# train = BatchStream(\"testing_data.json\")"
      ],
      "metadata": {
        "id": "XHhfAb6nILfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajKLIV6hsPLC"
      },
      "outputs": [],
      "source": [
        "!pip install d2l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqNZmkW_t0Tq"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "# from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbjs5EqS4GCx"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_dim, output_dim, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.n_layers, batch_size, self.hidden_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rnn_model(model, training_data, testing_data, epochs, batch_size, learning_rate, device):\n",
        "    model = model.to(device)\n",
        "    loss_function = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Adam written in research plan\n",
        "\n",
        "    training_batches = make_batches(training_data, model.input_size, batch_size=batch_size)\n",
        "    testing_batches = make_batches(testing_data, model.input_size, batch_size=batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in training_batches:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = torch.tensor(inputs).float().to(device)\n",
        "            targets = torch.tensor(targets).float().to(device)\n",
        "\n",
        "            hidden = model.init_hidden(inputs.size(0)).to(device)\n",
        "            outputs, _ = model(inputs, hidden)\n",
        "\n",
        "            loss = loss_function(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            print(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in testing_batches:\n",
        "                inputs, targets = batch\n",
        "                inputs = torch.tensor(inputs).float().to(device)\n",
        "                targets = torch.tensor(targets).float().to(device)\n",
        "\n",
        "                hidden = model.init_hidden(inputs.size(0)).to(device)\n",
        "                outputs, _ = model(inputs, hidden)\n",
        "\n",
        "                loss = loss_function(outputs, targets)\n",
        "                test_loss += loss.item()\n",
        "        if (len(training_batches) > 0 and len(testing_batches>0)):\n",
        "          print(f\"Epoch:, {epoch+1}/{epochs}, Train Loss: {train_loss/len(training_batches)}, Test Loss: {test_loss/len(testing_batches)}\")\n",
        "        else:\n",
        "          print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}, Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "id": "gl2c4G07M5Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training[0])\n",
        "print(len(training[0][0]))\n",
        "print(testing[0])"
      ],
      "metadata": {
        "id": "Em1JSQrEd-kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(training[0][1]) + len(training[0][0])  # size of state and gate encoding\n",
        "hidden_dim = 64\n",
        "output_dim = len(training[0])  # size of gate encoding\n",
        "n_layers = 1\n",
        "\n",
        "model = RNN(input_size, hidden_dim, output_dim, n_layers)\n",
        "epochs = 50\n",
        "batch_size = 60\n",
        "learning_rate = 0.01\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_rnn_model(model, training[0], testing[0], epochs, batch_size, learning_rate, device)"
      ],
      "metadata": {
        "id": "rJ-_SbJwNaFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_9IWIjuNcRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}